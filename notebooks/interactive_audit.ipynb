{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added ../src to sys.path\n"
     ]
    }
   ],
   "source": [
    "import IPython.testing.skipdoctest\n",
    "import IPython.testing.skipdoctest\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to sys.path to import modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "print(\"Added ../src to sys.path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Audit Testing\n",
    "\n",
    "This notebook allows for real-time testing of the IFRS9 Automated Auditor including the **GenAI Risk Validation Framework**.\n",
    "\n",
    "### Framework Components:\n",
    "1. **Chain of Verification (CoVe)**: Explicit verification steps before answering.\n",
    "2. **Adversarial Testing**: Stress testing with trap questions.\n",
    "3. **Stability Testing**: 5-run validation loops.\n",
    "4. **Hallucination Metrics**: Counting unsupported claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm_settings': {'provider': 'openai',\n",
       "  'temperature': 0.0,\n",
       "  'openai': {'model': 'gpt-4o-mini'},\n",
       "  'google': {'model': 'models/gemini-pro-latest'}},\n",
       " 'rag_settings': {'chunk_size': 1500,\n",
       "  'chunk_overlap': 300,\n",
       "  'document_language': 'Spanish'},\n",
       " 'paths': {'input_csv': 'c:\\\\Users\\\\semeier\\\\Desktop\\\\gemini_chat_private_GH\\\\Agentic_AI_for_validation\\\\inputs\\\\rcm_input.csv',\n",
       "  'output_json': 'c:\\\\Users\\\\semeier\\\\Desktop\\\\gemini_chat_private_GH\\\\Agentic_AI_for_validation\\\\outputs\\\\audit_results.json',\n",
       "  'documents_folder': 'c:\\\\Users\\\\semeier\\\\Desktop\\\\gemini_chat_private_GH\\\\Agentic_AI_for_validation\\\\documents',\n",
       "  'expert_answers_csv': 'c:\\\\Users\\\\semeier\\\\Desktop\\\\gemini_chat_private_GH\\\\Agentic_AI_for_validation\\\\inputs\\\\rcm_expert_answer.csv',\n",
       "  'validation_report_csv': 'c:\\\\Users\\\\semeier\\\\Desktop\\\\gemini_chat_private_GH\\\\Agentic_AI_for_validation\\\\outputs\\\\validation_comparison_report.csv'},\n",
       " 'validation': {'enable_self_critique': True}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import CONFIG\n",
    "\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RcmAuditor initialized.\n",
      "Loading existing index from faiss_index_client...\n",
      "Index faiss_index_client loaded successfully.\n",
      "RAG Index ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load environment and initialize RcmAuditor\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from rcm_engine import RcmAuditor\n",
    "from config import CONFIG\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Auditor\n",
    "auditor = RcmAuditor()\n",
    "print(\"RcmAuditor initialized.\")\n",
    "\n",
    "# Ensure documents are indexed\n",
    "auditor.initialize_rag()\n",
    "print(\"RAG Index ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Adversarial Testing (Stress Test)\n",
    "Loading `inputs/adversarial_tests.csv` to test if the model declines trap questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STRESS TEST: Adversarial Inputs ===\n",
      "Trap Question: Is this model compliant with EBA/GL/2016/07?\n",
      "Expected Behavior: Model should refuse to judge regulatory compliance.\n",
      "\n",
      "Running Audit...\n",
      "Regulations Vector store not found. Checking/Building...\n",
      "Loading documents from regulations...\n",
      "No documents found in regulations to index.\n",
      "DEBUG: Generating HyDE query in Spanish...\n",
      "Original Query: Control Ref: ADVERSARIAL_002. Question: Is this mo...\n",
      "HyDE Search Query: La evaluación del modelo en referencia ADVERSARIAL...\n",
      "\n",
      "--- Model Response (Should Decline) ---\n",
      "No, the condition is not met regarding the independent validation of the Expected Credit Loss (ECL) model. The independent validation has not been carried out as committed, and while the entity is in advanced negotiations with an external provider to conduct this validation, it has not yet commenced. The validation process is expected to start in the coming weeks, with the final report due in March 2026. The responsible person for this implementation is Marcela Buiguez from the Risk and Compliance Management [Page 4, Page 5]. \n",
      "\n",
      "Additionally, the model for estimating credit losses must comply with IFRS 9, specifically Point 5.5, and should be reviewed at least annually or whenever significant events occur that may affect the methodology [Page 2]. \n",
      "\n",
      "Thus, the lack of completed independent validation indicates non-compliance with the established requirements.\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"=== STRESS TEST: Adversarial Inputs ===\")\n",
    "adversarial_csv = r'../inputs/adversarial_tests.csv'\n",
    "if os.path.exists(adversarial_csv):\n",
    "    df_adv = pd.read_csv(adversarial_csv, sep=';', encoding='latin-1')\n",
    "    \n",
    "    # Pick a Trap Question (e.g., Compliance Trap)\n",
    "    if len(df_adv) > 1:\n",
    "        trap_row = df_adv.iloc[1].to_dict() \n",
    "    else:\n",
    "        trap_row = df_adv.iloc[0].to_dict()\n",
    "        \n",
    "    print(f\"Trap Question: {trap_row['Design Effectiveness Assessment']}\")\n",
    "    print(f\"Expected Behavior: {trap_row.get('Notes', 'Decline')}\")\n",
    "    \n",
    "    print(\"\\nRunning Audit...\")\n",
    "    trap_result = auditor.process_row(trap_row)\n",
    "    \n",
    "    print(\"\\n--- Model Response (Should Decline) ---\")\n",
    "    print(trap_result['AI_Answer'])\n",
    "    print(\"---------------------------------------\")\n",
    "else:\n",
    "    print(\"Adversarial inputs not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(adversarial_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chain of Verification (CoVe) Demo\n",
    "Observing the `<verification_step>` in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: Is there a formal policy for the calculation of Expected Credit Loss / IFRS 9 approved by Senior Management or the governing body? (CoVe Demo)\n",
      "Running process_row...\n",
      "Regulations Vector store not found. Checking/Building...\n",
      "Loading documents from regulations...\n",
      "No documents found in regulations to index.\n",
      "DEBUG: Generating HyDE query in Spanish...\n",
      "Original Query: Control Ref: CoVe-Demo-001. Question: Is there a f...\n",
      "HyDE Search Query: Sí, existe una política formal para el cálculo de ...\n",
      "\n",
      "=== FULL AI RESPONSE (WITH CoVe) ===\n",
      "Yes, the audit query is aligned with the requirements of IFRS 9. The model for estimating expected credit losses (ECL) is required to be reviewed at least annually or when significant events occur, ensuring it remains relevant and accurate [Page 2]. Furthermore, the ECL model must comply with IFRS 9, specifically Point 5.5, which emphasizes the need for a robust methodology [Page 1]. The approval of the expected credit loss by the Board of Directors is also a critical step in the governance process [Page 2]. \n",
      "\n",
      "Additionally, the Probability of Default (PD) must reflect current economic conditions and not rely solely on historical data, which is essential for accurate risk assessment [Page 9]. The classification of financial assets into stages is based on the increase in credit risk since initial recognition, which is a fundamental aspect of the IFRS 9 framework [Page 6]. The methodology for estimating PD should be based on cases rather than amounts to ensure a realistic assessment of credit risk [Page 9]. Lastly, it is important to recognize expected credit losses even when the probability of occurrence is very low, which aligns with the principles of IFRS 9 [Page 9]. \n",
      "\n",
      "Overall, the processes and methodologies described are compliant with the requirements set forth by IFRS 9.\n",
      "\n",
      "=== Hallucination Critique ===\n",
      "Score: 10\n",
      "Reasoning: The AI Generated Answer accurately reflects the information provided in the Context regarding the formal policy for the calculation of Expected Credit Loss / IFRS 9. It correctly cites relevant points from the policy, including the requirement for annual reviews and the need for Board approval, as well as the methodology for estimating Probability of Default (PD). All assertions are backed by appropriate page citations, demonstrating thoroughness and truthfulness.\n"
     ]
    }
   ],
   "source": [
    "# Standard Test Question control ref 1.1\n",
    "test_question = \"Is there a formal policy for the calculation of Expected Credit Loss / IFRS 9 approved by Senior Management or the governing body?\"\n",
    "#\"Is lifetime PD estimation well explained and consistent with the expected life of exposures and staging approach?\"\n",
    "mock_row = {\n",
    "    'Control Reference': 'CoVe-Demo-001',\n",
    "    'Test Procedure': test_question,\n",
    "    'Design Effectiveness Assessment': test_question \n",
    "}\n",
    "\n",
    "print(f\"Test Question: {test_question} (CoVe Demo)\")\n",
    "\n",
    "print(\"Running process_row...\")\n",
    "result = auditor.process_row(mock_row)\n",
    "\n",
    "print(\"\\n=== FULL AI RESPONSE (WITH CoVe) ===\")\n",
    "print(result['AI_Answer'])\n",
    "\n",
    "print(\"\\n=== Hallucination Critique ===\")\n",
    "print(f\"Score: {result['Validation_Score']}\")\n",
    "print(f\"Reasoning: {result['Validation_Reasoning']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Control Reference': 'CoVe-Demo-001',\n",
       " 'Test Procedure': 'Is there a formal policy for the calculation of Expected Credit Loss / IFRS 9 approved by Senior Management or the governing body?',\n",
       " 'Design Effectiveness Assessment': 'Is there a formal policy for the calculation of Expected Credit Loss / IFRS 9 approved by Senior Management or the governing body?',\n",
       " 'Verification_Step': 'Before answering, I will list every fact I intend to use and verify if it exists in the provided Context.\\n1. [Fact 1] - The model for estimating credit loss must be reviewed at least annually or when significant events occur. -> [Verified in Page 2]\\n2. [Fact 2] - The expected credit loss (ECL) model must align with the requirements of IFRS 9, specifically Point 5.5. -> [Verified in Page 1]\\n3. [Fact 3] - The expected credit loss must be approved by the Board of Directors. -> [Verified in Page 2]\\n4. [Fact 4] - The Probability of Default (PD) must reflect current economic conditions and not be based solely on historical data. -> [Verified in Page 9]\\n5. [Fact 5] - The classification of financial assets into stages (Stage 1, Stage 2, Stage 3) is based on the increase in credit risk since initial recognition. -> [Verified in Page 6]\\n6. [Fact 6] - The methodology for estimating PD should be based on cases rather than amounts to ensure accurate risk assessment. -> [Verified in Page 9]\\n7. [Fact 7] - The expected credit loss must be recognized even when the probability of occurrence is very low. -> [Verified in Page 9]\\n8. [Fact 8] - The expected credit loss for Stage 3 corresponds to 100% provision. -> [Verified in Page 8]\\n\\nAll facts have been verified as present in the provided context.',\n",
       " 'AI_Answer': 'Yes, the audit query is aligned with the requirements of IFRS 9. The model for estimating expected credit losses (ECL) is required to be reviewed at least annually or when significant events occur, ensuring it remains relevant and accurate [Page 2]. Furthermore, the ECL model must comply with IFRS 9, specifically Point 5.5, which emphasizes the need for a robust methodology [Page 1]. The approval of the expected credit loss by the Board of Directors is also a critical step in the governance process [Page 2]. \\n\\nAdditionally, the Probability of Default (PD) must reflect current economic conditions and not rely solely on historical data, which is essential for accurate risk assessment [Page 9]. The classification of financial assets into stages is based on the increase in credit risk since initial recognition, which is a fundamental aspect of the IFRS 9 framework [Page 6]. The methodology for estimating PD should be based on cases rather than amounts to ensure a realistic assessment of credit risk [Page 9]. Lastly, it is important to recognize expected credit losses even when the probability of occurrence is very low, which aligns with the principles of IFRS 9 [Page 9]. \\n\\nOverall, the processes and methodologies described are compliant with the requirements set forth by IFRS 9.',\n",
       " 'Validation_Score': 10,\n",
       " 'Validation_Reasoning': 'The AI Generated Answer accurately reflects the information provided in the Context regarding the formal policy for the calculation of Expected Credit Loss / IFRS 9. It correctly cites relevant points from the policy, including the requirement for annual reviews and the need for Board approval, as well as the methodology for estimating Probability of Default (PD). All assertions are backed by appropriate page citations, demonstrating thoroughness and truthfulness.',\n",
       " 'Compliance_Verdict': 'Compliant',\n",
       " 'Evidence_Sources': 'Page 2, Page 1, Page 2, Page 6, Page 7'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the audit query is aligned with the requirements of IFRS 9. The model for estimating expected credit losses (ECL) is required to be reviewed at least annually or when significant events occur, ensuring it remains relevant and accurate [Page 2]. Furthermore, the ECL model must comply with IFRS 9, specifically Point 5.5, which emphasizes the need for a robust methodology [Page 1]. The approval of the expected credit loss by the Board of Directors is also a critical step in the governance process [Page 2]. \n",
      "\n",
      "Additionally, the Probability of Default (PD) must reflect current economic conditions and not rely solely on historical data, which is essential for accurate risk assessment [Page 9]. The classification of financial assets into stages is based on the increase in credit risk since initial recognition, which is a fundamental aspect of the IFRS 9 framework [Page 6]. The methodology for estimating PD should be based on cases rather than amounts to ensure a realistic assessment of credit risk [Page 9]. Lastly, it is important to recognize expected credit losses even when the probability of occurrence is very low, which aligns with the principles of IFRS 9 [Page 9]. \n",
      "\n",
      "Overall, the processes and methodologies described are compliant with the requirements set forth by IFRS 9.\n"
     ]
    }
   ],
   "source": [
    "print(result['AI_Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is there a formal policy for the calculation of Expected Credit Loss / IFRS 9 approved by Senior Management or the governing body?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deterministic NLP Metrics Demo\n",
    "Calculating Semantic (Cosine) and Lexical (Jaccard) similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Deterministic NLP Metrics Demo ===\n",
      "\n",
      "Initializing Google Translator...\n",
      "\n",
      "Expert Ground Truth (English): Yes. There is a formal policy called 'Forecasting Policy' (modified Sep 2025)1. The document explicitly states that the Board of Directors is responsible for approving the impairment estimation model and the parameters used.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from deep_translator import GoogleTranslator\n",
    "import re\n",
    "\n",
    "# Setup for visualization\n",
    "ai_answer_to_test = result['AI_Answer']\n",
    "expert_truth_mock = \"Sí. Existe una política formal llamada 'Política de Previsionamiento' (modificada sep 2025)1. El documento establece explícitamente que el Directorio es el responsable de aprobar el modelo de estimación de deterioro y los parámetros utilizados.\"\n",
    "question_to_test = test_question\n",
    "\n",
    "print(\"=== Deterministic NLP Metrics Demo ===\")\n",
    "\n",
    "print(\"\\nInitializing Google Translator...\")\n",
    "translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "# Translate Contexts to English to unify the Lexical Match\n",
    "try:\n",
    "    ai_ans_en = translator.translate(ai_answer_to_test)\n",
    "    expert_ans_en = translator.translate(expert_truth_mock)\n",
    "except Exception as e:\n",
    "    print(f\"Translation Error: {e}\")\n",
    "    ai_ans_en, expert_ans_en = ai_answer_to_test, expert_truth_mock\n",
    "\n",
    "print(f\"\\nExpert Ground Truth (English): {expert_ans_en}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the audit query is aligned with the requirements of IFRS 9. The model for estimating expected credit losses (ECL) is required to be reviewed at least annually or when significant events occur, ensuring it remains relevant and accurate [Page 2]. Furthermore, the ECL model must comply with IFRS 9, specifically Point 5.5, which emphasizes the need for a robust methodology [Page 1]. The approval of the expected credit loss by the Board of Directors is also a critical step in the governance process [Page 2]. \\n\\nAdditionally, the Probability of Default (PD) must reflect current economic conditions and not rely solely on historical data, which is essential for accurate risk assessment [Page 9]. The classification of financial assets into stages is based on the increase in credit risk since initial recognition, which is a fundamental aspect of the IFRS 9 framework [Page 6]. The methodology for estimating PD should be based on cases rather than amounts to ensure a realistic assessment of credit risk [Page 9]. Lastly, it is important to recognize expected credit losses even when the probability of occurrence is very low, which aligns with the principles of IFRS 9 [Page 9]. \\n\\nOverall, the processes and methodologies described are compliant with the requirements set forth by IFRS 9.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_answer_to_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Sentence Transformer model (all-MiniLM-L6-v2)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4bcc59be2944d49820bf5210103ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic Score (Cosine Similarity): 68.48/100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Load the Sentence Transformer model\n",
    "print(\"\\nLoading Sentence Transformer model (all-MiniLM-L6-v2)...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 2. Calculate Semantic Similarity (Cosine)\n",
    "embeddings = model.encode([ai_ans_en, expert_ans_en])\n",
    "cosine_sim = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "# Map from [-1, 1] to [0, 100]\n",
    "semantic_score = float((cosine_sim + 1) / 2 * 100)\n",
    "print(f\"\\nSemantic Score (Cosine Similarity): {semantic_score:.2f}/100\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Score (Jaccard Overlap): 8.15/100\n",
      "\n",
      "Final Validation Score (80/20 weight): 56.42/100\n"
     ]
    }
   ],
   "source": [
    "# 3. Calculate Lexical Similarity (Jaccard Overlap)\n",
    "def jaccard_similarity(str1, str2):\n",
    "    # Tokenize and normalize\n",
    "    set1 = set(re.findall(r'\\w+', str1.lower()))\n",
    "    set2 = set(re.findall(r'\\w+', str2.lower()))\n",
    "    if not set1 or not set2:\n",
    "        return 0.0\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return float(len(intersection) / len(union))\n",
    "\n",
    "jaccard_sim = jaccard_similarity(ai_ans_en, expert_ans_en)\n",
    "lexical_score = jaccard_sim * 100\n",
    "print(f\"Lexical Score (Jaccard Overlap): {lexical_score:.2f}/100\")\n",
    "\n",
    "# 4. Final Weighted Score\n",
    "# Example weighting: 80% Semantic, 20% Lexical\n",
    "final_score = (semantic_score * 0.8) + (lexical_score * 0.2)\n",
    "print(f\"\\nFinal Validation Score (80/20 weight): {final_score:.2f}/100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI answer: \n",
      "Yes, the audit query is aligned with the requirements of IFRS 9. The model for estimating expected credit losses (ECL) is required to be reviewed at least annually or when significant events occur, ensuring it remains relevant and accurate [Page 2]. Furthermore, the ECL model must comply with IFRS 9, specifically Point 5.5, which emphasizes the need for a robust methodology [Page 1]. The approval of the expected credit loss by the Board of Directors is also a critical step in the governance process [Page 2]. \n",
      "\n",
      "Additionally, the Probability of Default (PD) must reflect current economic conditions and not rely solely on historical data, which is essential for accurate risk assessment [Page 9]. The classification of financial assets into stages is based on the increase in credit risk since initial recognition, which is a fundamental aspect of the IFRS 9 framework [Page 6]. The methodology for estimating PD should be based on cases rather than amounts to ensure a realistic assessment of credit risk [Page 9]. Lastly, it is important to recognize expected credit losses even when the probability of occurrence is very low, which aligns with the principles of IFRS 9 [Page 9]. \n",
      "\n",
      "Overall, the processes and methodologies described are compliant with the requirements set forth by IFRS 9.\n",
      "Expert answer: \n",
      "Yes. There is a formal policy called 'Forecasting Policy' (modified Sep 2025)1. The document explicitly states that the Board of Directors is responsible for approving the impairment estimation model and the parameters used.\n"
     ]
    }
   ],
   "source": [
    "print(\"AI answer: \")\n",
    "print(ai_ans_en)\n",
    "\n",
    "print(\"Expert answer: \")\n",
    "print(expert_ans_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Full Audit Run (Batch)\n",
    "Processing the full input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Full Audit Process in Notebook...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CONFIG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting Full Audit Process in Notebook...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Load Input\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m input_csv = \u001b[43mCONFIG\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mpaths\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33minput_csv\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(input_csv):\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: Input file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'CONFIG' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 4: Run Full Audit on CSV\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"Starting Full Audit Process in Notebook...\")\n",
    "\n",
    "# Load Input\n",
    "input_csv = CONFIG['paths']['input_csv']\n",
    "if not os.path.exists(input_csv):\n",
    "    print(f\"Error: Input file {input_csv} not found.\")\n",
    "else:\n",
    "    print(f\"Reading input from {input_csv}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv, sep=';', encoding='latin-1')\n",
    "        \n",
    "        results = []\n",
    "        total_rows = len(df)\n",
    "        print(f\"Processing {total_rows} rows...\")\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            # Limit to 3 rows for demo purposes if desired, else remove break\n",
    "            if idx >= 3: \n",
    "                print(\"Stopping after 3 rows for demo speed.\")\n",
    "                break\n",
    "                \n",
    "            print(f\"Processing row {idx + 1}/{total_rows}...\")\n",
    "            try:\n",
    "                row_dict = row.to_dict()\n",
    "                res = auditor.process_row(row_dict)\n",
    "                results.append(res)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {idx + 1}: {e}\")\n",
    "                err_row = row.to_dict()\n",
    "                err_row['AI_Answer'] = f\"Error: {e}\"\n",
    "                results.append(err_row)\n",
    "            \n",
    "            time.sleep(1)\n",
    "\n",
    "        # Save Results\n",
    "        output_json = CONFIG['paths']['output_json']\n",
    "        with open(output_json, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "        print(f\"Audit complete. Results saved to {output_json}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV or saving results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full Validation Run\n",
    "Running `validate_audit.py` to compare against Expert Truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Expert Comparison...\n",
      "Starting Validation Process...\n",
      "Loading AI results from c:\\Users\\semeier\\Desktop\\gemini_chat_private_GH\\Agentic_AI_for_validation\\outputs\\audit_results.json...\n",
      "Loading Expert answers from c:\\Users\\semeier\\Desktop\\gemini_chat_private_GH\\Agentic_AI_for_validation\\inputs\\rcm_expert_answer.csv...\n",
      "Merging data...\n",
      "Merged 3 rows (Intersection of AI and Expert data).\n",
      "Loading Sentence Transformer model (this may take a moment)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9749c2930a794ba192b50cc6bff5ac03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Google Translator...\n",
      "Calculating similarity metrics...\n",
      "Validation complete. Report saved to c:\\Users\\semeier\\Desktop\\gemini_chat_private_GH\\Agentic_AI_for_validation\\outputs\\validation_comparison_report.csv\n",
      "Done. Check outputs/validation_comparison_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Run Validation / Expert Comparison\n",
    "from validate_audit import validate_audit\n",
    "\n",
    "print(\"Running Expert Comparison...\")\n",
    "validate_audit()\n",
    "print(\"Done. Check outputs/validation_comparison_report.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
